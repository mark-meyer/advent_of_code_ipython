{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50ec931e-9d0a-4e28-a302-513e3b5d48d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cecf488f-f2ce-406e-9ec4-6cf744be8991",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse(lines):\n",
    "    blocks = []\n",
    "    for line in lines:\n",
    "        col, row = line.split(',')\n",
    "        blocks.append(Point(int(col), int(row)))\n",
    "    return blocks\n",
    "\n",
    "class Point(NamedTuple):\n",
    "    col: int\n",
    "    row: int\n",
    "\n",
    "    def __add__(self, other):\n",
    "        return Point(self.col + other.col, self.row + other.row)\n",
    "        \n",
    "    def neighbors(self, h, w):\n",
    "        for p in (Point(0, 1), Point(0, -1), Point(1, 0), Point(-1, 0)):\n",
    "            p = p + self\n",
    "            if 0 <= p.col < h and 0 <= p.row < w:\n",
    "                yield p\n",
    "\n",
    "def draw(blocks, h, w, highlight=None):\n",
    "    for r in range(h):\n",
    "        for c in range(w):\n",
    "            if Point(c, r) == highlight:\n",
    "                print('O', end='')\n",
    "            elif Point(c, r) in blocks:\n",
    "                print('#', end='')\n",
    "            else:\n",
    "                print('.', end='')\n",
    "        print('\\n', end='')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85e2964-659d-49dd-9530-beed4518e183",
   "metadata": {},
   "source": [
    "## Part one\n",
    "\n",
    "Hmm, just breadth first searchâ€¦wonder what's coming next?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48274f7e-c8bd-40b6-bf20-11c9eb4fbf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bfs(start, end, bytes, h, w):\n",
    "    \n",
    "    blocks = set(bytes)\n",
    "    seen = set([start])\n",
    "    \n",
    "    current_time = 0\n",
    "    d = deque([(start, 0)])\n",
    "\n",
    "    while d:\n",
    "        loc, time = d.popleft()\n",
    "        if loc == end:\n",
    "            return loc, time\n",
    "        \n",
    "        for n in loc.neighbors(h, w):\n",
    "            if n in blocks or n in seen:\n",
    "                continue\n",
    "            d.append((n, time + 1))\n",
    "            seen.add(n)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34e9d0b-e07e-4144-8ce9-b0effb0ba8fd",
   "metadata": {},
   "source": [
    "### Sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6e0ce8d-9a1c-4570-af4d-56dc1be3da1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = '''5,4\n",
    "4,2\n",
    "4,5\n",
    "3,0\n",
    "2,1\n",
    "6,3\n",
    "2,4\n",
    "1,5\n",
    "0,6\n",
    "3,3\n",
    "2,6\n",
    "5,1\n",
    "1,2\n",
    "5,5\n",
    "2,5\n",
    "6,5\n",
    "1,4\n",
    "0,4\n",
    "6,4\n",
    "1,1\n",
    "6,1\n",
    "1,0\n",
    "0,5\n",
    "1,6\n",
    "2,0'''.split('\\n')\n",
    "\n",
    "SAMPLE_HEIGHT = 7\n",
    "SAMPLE_WIDTH = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6a163d5-91d0-4320-9554-fd9ed9351a1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...#...\n",
      "..#..#.\n",
      "....#..\n",
      "...#..#\n",
      "..#..#.\n",
      ".#..#..\n",
      "#.#....\n",
      "Finished at Point(col=6, row=6) in 22 steps\n"
     ]
    }
   ],
   "source": [
    "\n",
    "all_bytes = parse(s)\n",
    "some_bytes = all_bytes[:12]\n",
    "\n",
    "draw(some_bytes, SAMPLE_HEIGHT,SAMPLE_WIDTH)\n",
    "\n",
    "p, time = bfs(\n",
    "    Point(0, 0),\n",
    "    Point(6, 6),\n",
    "    some_bytes,\n",
    "    SAMPLE_HEIGHT,\n",
    "    SAMPLE_WIDTH\n",
    ")\n",
    "print(f\"Finished at {p} in {time} steps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "332669e7-a091-436b-9a63-6c3c46338f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished at Point(col=70, row=70) in 302 steps\n"
     ]
    }
   ],
   "source": [
    "with open('input_files/18.txt') as f:\n",
    "    raw = f.read().splitlines()\n",
    "\n",
    "all_bytes = parse(raw)\n",
    "some_bytes = all_bytes[:1024]\n",
    "\n",
    "HEIGHT = 71\n",
    "WIDTH = 71\n",
    "\n",
    "p, time = bfs(\n",
    "    Point(0, 0),\n",
    "    Point(70, 70),\n",
    "    some_bytes,\n",
    "    HEIGHT,\n",
    "    WIDTH\n",
    ")\n",
    "print(f\"Finished at {p} in {time} steps\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e71f14-71a0-43b2-8c6b-24bb016088ab",
   "metadata": {},
   "source": [
    "## Part two\n",
    "\n",
    "The obvious way of running bfs after each additional dropped byte works, but is **very** slow on the big input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd078552-5734-43b6-882a-33ce3d9acb3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished at step 21. Last byte: Point(col=6, row=1)\n"
     ]
    }
   ],
   "source": [
    "all_bytes = parse(s)\n",
    "\n",
    "for i in range(1, len(all_bytes)):\n",
    "    r = bfs(\n",
    "        Point(0, 0),\n",
    "        Point(6, 6),\n",
    "        all_bytes[:i],\n",
    "        SAMPLE_HEIGHT,\n",
    "        SAMPLE_WIDTH\n",
    "    )\n",
    "    \n",
    "    if r is None:\n",
    "        print(f\"finished at step {i}. Last byte: {all_bytes[i-1]}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a952d83-90e9-45bc-884b-dd0074309f14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished at step 2856. Last byte: Point(col=24, row=32)\n"
     ]
    }
   ],
   "source": [
    "all_bytes = parse(raw)\n",
    "\n",
    "# This takes about 22 seconds!!\n",
    "for i in range(1, len(all_bytes)):\n",
    "    r = bfs(\n",
    "        Point(0, 0),\n",
    "        Point(70, 70),\n",
    "        all_bytes[:i],\n",
    "        HEIGHT,\n",
    "        WIDTH\n",
    "    )\n",
    "    \n",
    "    if r is None:\n",
    "        print(f\"finished at step {i}. Last byte: {all_bytes[i-1]}\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2236359-9fb9-4c06-9c1f-9f9da5616920",
   "metadata": {},
   "source": [
    "## A quick fix:\n",
    "Since we know the bytes will fall in an order like:\n",
    "\n",
    "```\n",
    "[unblocked, unblocked, unblocked, unblocked, BLOCKED, BLOCKED, BLOCKED]\n",
    "```\n",
    "\n",
    "We can just look for the first BLOCKED using binary search. BFS above returns None when there's no path. Do jsut look for the first time that happens and avoid searching the whole loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3565589d-9f6a-4e20-8537-76579222ea3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Point(col=24, row=32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bisect import bisect_left\n",
    "\n",
    "all_bytes = parse(raw)\n",
    "\n",
    "HEIGHT = 71\n",
    "WIDTH = 71\n",
    "\n",
    "\n",
    "first_blocked_index = bisect_left(\n",
    "    range(len(all_bytes)),\n",
    "    True,\n",
    "    key=lambda idx: bfs(Point(0, 0), Point(70, 70), all_bytes[:idx], HEIGHT, WIDTH) == None)\n",
    "\n",
    "all_bytes[first_blocked_index - 1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13b20b6-49f0-44ab-b83d-deb03f6b5a79",
   "metadata": {},
   "source": [
    "### Over-engineered, but curious how it is to solve this with disjoint sets\n",
    "\n",
    "\n",
    "This problem looks like a graph connectivity problem. At a certain point it will take only a single cut to partition the graph, which would make areas unreachable from others. Maybe we can start with all the bytes dropped with the knowledge that there is no path between the start and the end. Now make sets of all connected components.\n",
    "\n",
    "#### Two partitions \n",
    "\n",
    "```\n",
    "++++++#  \n",
    "+++++#o  \n",
    "++++#oo  \n",
    "+++#ooo  \n",
    "++#oooo  \n",
    "+#ooooo  \n",
    "#oooooo  \n",
    "```\n",
    "\n",
    "Starting with the above we can tell in constant time if removing a # connects the sets (thereby allowing a path) by checking if the neighbors of the # are in both sets. The sample problem only has two disconnected components when all the blocks are down. But the real problems has many. So the strategy here is:\n",
    "\n",
    "1. Use BFS to find all the disjoint sets with all the bytes dropped, keeping special track of the component with the start and end\n",
    "2. Look at each byte in reverse order\n",
    "3. Find its neighbors and all the sets containing those neighbors.\n",
    "4. If the sets include the sets with the start and stop point, we're done, removing this block allows a path\n",
    "5. Otherwise merge these partitions into a larger partition (paying attention to keep track of the start/stop paritions)\n",
    "\n",
    "This will eventually get to a point where removing the a block connects the start and stop. This was the last byte to drop blocking the path.\n",
    "\n",
    "Lists of sets may not be the best data structure. Perhaps the [Disjoint-set data structure](https://en.wikipedia.org/wiki/Disjoint-set_data_structure) would be even better.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a99cf0-0f2c-4110-93dc-d7d41183b42e",
   "metadata": {},
   "source": [
    "### Partition all points in the graph that are not in the set of bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ceb91b6e-936b-4d2c-be81-e24bea57560e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start: {Point(col=4, row=0), Point(col=0, row=0), Point(col=2, row=0), Point(col=3, row=0), Point(col=5, row=0), Point(col=1, row=0)}\n",
      "End: {Point(col=70, row=70), Point(col=69, row=70), Point(col=70, row=69)}\n",
      "distjoint? True\n"
     ]
    }
   ],
   "source": [
    "def find_points(start, all_points, h, w):\n",
    "    '''\n",
    "    Find all points reachable from the start point. This will \n",
    "    return a single connected component of the graph.\n",
    "    '''\n",
    "    \n",
    "    seen = set([start])\n",
    "    d = deque([start])\n",
    "\n",
    "    while d:\n",
    "        loc = d.popleft()\n",
    "        for n in loc.neighbors(h, w):\n",
    "            if n in seen or n not in all_points :\n",
    "                continue\n",
    "            d.append(n)\n",
    "            seen.add(n)\n",
    "            \n",
    "    return seen\n",
    "    \n",
    "def get_all_points(h, w, blocks):\n",
    "    '''\n",
    "    Helper to just get every grid point that is\n",
    "    not one of the falling bytes.\n",
    "    '''\n",
    "    all_points = set()\n",
    "    # every cooridinate in the space as a set of Point\n",
    "    for row in range(h):\n",
    "        for col in range(w):\n",
    "            all_points.add(Point(col, row))\n",
    "\n",
    "    # remove the fallen bytes\n",
    "    return  all_points - set(blocks)\n",
    "\n",
    "def make_partitions(points, h, w):\n",
    "    '''\n",
    "    Find all the connected components in the points.\n",
    "    '''\n",
    "    # Make start and end partitions manually to make it easier to track them\n",
    "    start_partition = find_points(Point(0, 0), all_points, h, w)\n",
    "    end_partition = find_points(Point(h-1, w-1), all_points, h, w)\n",
    "\n",
    "    # Be careful to make these easy to find\n",
    "    # We will always keep them in indices 0 and 1\n",
    "    partitions = [start_partition, end_partition]\n",
    "    \n",
    "    rest = all_points - start_partition.union(end_partition)\n",
    "    \n",
    "    while rest:\n",
    "        next_point = rest.pop()\n",
    "        next_partition = find_points(next_point, rest, h, w)\n",
    "        partitions.append(next_partition)\n",
    "        rest = rest - next_partition\n",
    "    \n",
    "    return partitions\n",
    "\n",
    "HEIGHT = 71\n",
    "WIDTH = 71\n",
    "\n",
    "all_bytes = parse(raw)\n",
    "\n",
    "all_points = get_all_points(HEIGHT, WIDTH, all_bytes)\n",
    "partitions = make_partitions(all_points, HEIGHT, WIDTH)\n",
    "\n",
    "print(\"Start:\", partitions[0])\n",
    "print(\"End:\", partitions[1])\n",
    "\n",
    "# These are disjoint, the goal is to connect them:\n",
    "print(\"distjoint?\", partitions[0].isdisjoint(partitions[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8ed6936a-0e57-4077-9faf-caebef9aa21d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Point(col=24, row=32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def merge_sets(partitions, blocks, h, w):\n",
    "    '''\n",
    "    Add points from blocks one by one until the first two partitions \n",
    "    are connected.\n",
    "    '''\n",
    "    # assuming start and end sets are in indices 0 and 1\n",
    "    block_set = set(all_bytes)\n",
    "    for b in reversed(blocks):\n",
    "        block_set.remove(b)\n",
    "        neighbors = set(n for n in b.neighbors(h, w) if n not in block_set)\n",
    "         \n",
    "        # indices of all partitions that overlap these neighbors\n",
    "        intersections = [i for i, s in enumerate(partitions) if s.intersection(neighbors)]\n",
    "        \n",
    "        if len(intersections) == 0:\n",
    "            # block is isolated in a larger group of blocks\n",
    "            partitions.append(set([b]))\n",
    "        elif 0 in intersections and 1 in intersections:\n",
    "            # we're done!\n",
    "            return b\n",
    "        else:\n",
    "            # merge newly connected components\n",
    "            s, *rest = intersections\n",
    "            partitions[s] = set.union(*[partitions[i] for i in intersections])\n",
    "            for j in rest:\n",
    "                partitions.pop(j)\n",
    "            partitions[s].add(b)\n",
    "\n",
    "merge_sets(partitions, all_bytes, HEIGHT, WIDTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba1f1fd5-fab9-43a1-b3c7-eae85fa9cbdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "......##....#.#.##.#..####...#...######..####..##..###.###.......#..##.\n",
      "######.#######.#.#################################.#.#############.####\n",
      ".##..#.#.#.#..##...#.#.#...#...#.##.#.#.#...##.###.#.#.#...####..#.#.#.\n",
      "####.#####.#.#.#####.###.#.###.###################.###.#.###.#.########\n",
      "#.##.##..#####.#.#.##..#.#...##..##.##########.##.#.##.#.#..#.###.##.##\n",
      "##.###.###.#################.#########.#.###############.###########.#.\n",
      "..#####..#.###..###..#.#.#...###...#.########..#.....###.#.#.#.#.#..#.#\n",
      ".###########.#.#######.###.#########.###########.#####################.\n",
      "..#..#.....##..#..##.###.##..#..##.#.#...#.#...#..##....#####.#.....###\n",
      "######.#.#####.#####.#######.#.#.###########.#####.###########.#####.#.\n",
      "####.###.#...#.##.##.#..#..#.######..#.#####.....#####..####.#.#...###.\n",
      ".###.#####.#.###############.#.#########.#.#.###.#####.#####.#########.\n",
      ".#.##.####.#.#.###.#.#...#.####.#..##.##...##..#.#...###.######..#.#.#.\n",
      "##.###.###.#######.#.#####.###################.#.###.#.#############.#.\n",
      ".####.###..#.#.###.#.#.#.#.#.#.#.##..#.#####.###......##.##.##..###.##.\n",
      ".###.###.#######.#.#####.###.###.#################.#####.#########.####\n",
      ".#####.#.###....##.#...#.#.#.###.#...#.#####.#...##.##.###..#...#.###..\n",
      "####.#.#####.#####.###########.#########.#######.#####.#############.#.\n",
      ".##..#.###.####..#...#.###..#..###...#..#####..##.###..###.#.....#...#.\n",
      "######.#.#####.#.#####.#.#######.###.#####.#############.###.#########.\n",
      "##...###..##...###.#.##.####.#.####.####..####.#.#.#.#.#...#....####.#.\n",
      "################.###.#########.###.#########.#.###.#.#####.#.#####.#.#.\n",
      ".###.#.#.#.#...#.#.#.#.#..##...#...#.....##.####.#.#.###.#.#.#...#..###\n",
      ".#######.#######.#.#.###########.###.#.###########.#####.###.###.#####.\n",
      "...###.##..#.###.#.#.#...##..#.###.###....####..##..####.##..###.....#.\n",
      "######.#########.###.###.#.###############.#.#########.###.###.########\n",
      ".#####.###.#.#.##..##..#...#...#.#...#...###.#####.#..###....#.#...#...\n",
      ".###.###.###.#.###.###########.#######.#.#####.###.###########.########\n",
      "##.#.##.###.####.#...........#...#.#...###.#.#.#.#..#......#...#.#.###.\n",
      ".#####.#########.###########.#####.#####.#.#.#.#.#########.#.###.######\n",
      "#.##.....#..#....##...###...##.....##..#.#.#.#.###..##..##...#...#..##.\n",
      "##.#############.#.###.#######.#######.###.#.#.#.#.#.###.#####.#####.#.\n",
      "#.####..##.#.#.#.#.#.#.##.##.#.##...##.##..###.#...##..#.#...#.#.###.#.\n",
      ".###.#.#.#.#####.#####.#####.#######.#################.#.#########.###.\n",
      ".##.######.#.##.#######.#.##...#.#....##.##.#..####..###.#.#..#.##.###.\n",
      "########.###.###########################.###########.#.#.###.##########\n",
      "...###.###.####..###..#..#.#..#.######...###.#..######.#.#.#.###.##.##.\n",
      "############.#####.#####.#################.###.###.#######.############\n",
      "##.##.##.#.#.###.#.###.###.###.#.##.##.#..#####.#..#...#.#....##.#.###.\n",
      ".#####.#.#.###.#.###.#.###########.###.#.###.###########.#############.\n",
      "##.#.#.#..###.##.##..###.#.#.#.###.##..#.#...##...###..#.###.###.###.##\n",
      "################.#.###.###################.###########.#.#########.####\n",
      "#...##.####...#..#.#.#.#.#.###..##.#...#####.#####.#####.#.##..####....\n",
      "######.#.#############.###.###.#####.#.#.###########.#.#########.#####.\n",
      "##.#...##....##..######....###.##.##.#.#..#..#...###.#####.....##..##..\n",
      ".#.#.###############.###############.#.#########.###.###.###.#######.#.\n",
      "##.#...##.#######.##.#.#..##.#...#.###.##.#######..###.#...##.#..#.#.##\n",
      "##########.#####.#.###.###.#.#.###.###########.###.####################\n",
      "##..##...#..##...###..##.#.#.#...#..##.###.....###...#..#.#..##..####..\n",
      ".###.#.#.###############.#.#.#######.#.#########.###.#######.#####.####\n",
      "#..#...#.#.###.#.#...#.#.#.#...#..##.##......#.#.###.#..########..##.#.\n",
      "##.#####.#.###.#.#####.###########################.#####.##############\n",
      ".#.#.#.#.#..####..#.###..#..#.##...#...#####...#.#.#...##..##..###.....\n",
      "##.#######.#############.###.#.###.#.###.###########.#########.#.#.###.\n",
      "..##.#.#...####....###.#.#.####..#.#.#.##.##.#.#..####.#....####.#.#..#\n",
      "########.###.#############.#########.#####.#####.###.###########.#.###.\n",
      ".#.#.#####....############.#.#.#..###..#.##..#...#.#..####.#...#..##.#.\n",
      ".#.###############.#.###.###.#####.#.#########.#########.###.#.#####.##\n",
      "####..##.#.#...#..##.#.######.####..##..##.###...#...#....########...##\n",
      ".#.#######.#.#.#########.#####.#########.###########.#####.#######.####\n",
      "##.###.##..#.#.#####.###..####...####..#####.....#.##.##.#.#.##..##....\n",
      ".###########.#########.#################.#.#.###.#####.#####.#####.###.\n",
      ".#..#.##.#...##..#.#.##.#..#..##.#.###.#.###.#.###.######..###.#.#.#..#\n",
      "########.#########.#######.###.#.###.###.###.#.#######.#####.#.#######.\n",
      "#..#.#.####.#..###.#.....##..#.###...###...#....######.#.#.###..##...##\n",
      "######.#############.#########.#.#########.#####.#.#######.#.#########.\n",
      ".#...#.#.#.....##..#.##.#..###.#...##..#.###.###.###...#.####..##....##\n",
      "##.#######.#####.#.#.#.#.#######.#.#.#.#.#######.#####.###.############\n",
      ".#.##.#.####...#.#...###.###...###.#.##..##..#.#######.#.########..#..#\n",
      ".#########.###.#######.###.#######.#.###################.#.###########.\n",
      "..#.#.##.##.##......##...#....#.##.#.#.....#.#.#.....##..#####.####.#..\n"
     ]
    }
   ],
   "source": [
    "draw(all_bytes, HEIGHT, WIDTH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
